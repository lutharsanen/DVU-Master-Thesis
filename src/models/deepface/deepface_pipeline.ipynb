{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bearing-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enlargen_image(border):\n",
    "    border[0]-=20\n",
    "    border[1]-=20\n",
    "    border[2]+=20\n",
    "    border[3]+=20\n",
    "    return border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daily-north",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face_1\n",
      "WARNING: Representations for images in  /media/lkunam/DVU-Challenge/HLVU/movie_knowledge_graph/honey/image/Person/  folder were previously stored in  representations_vgg_face.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  54  representations found in  representations_vgg_face.pkl\n",
      "No face was able to be matched\n",
      "/media/lkunam/DVU-Challenge/HLVU/keyframes/shot_keyf/honey/honey-1/shot_0007/shot_0007_img_1.jpg\n",
      "face_1\n",
      "WARNING: Representations for images in  /media/lkunam/DVU-Challenge/HLVU/movie_knowledge_graph/honey/image/Person/  folder were previously stored in  representations_vgg_face.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  54  representations found in  representations_vgg_face.pkl\n",
      "No face was able to be matched\n",
      "/media/lkunam/DVU-Challenge/HLVU/keyframes/shot_keyf/honey/honey-1/shot_0006/shot_0006_img_2.jpg\n",
      "face_1\n",
      "WARNING: Representations for images in  /media/lkunam/DVU-Challenge/HLVU/movie_knowledge_graph/honey/image/Person/  folder were previously stored in  representations_vgg_face.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  54  representations found in  representations_vgg_face.pkl\n",
      "No face was able to be matched\n",
      "/media/lkunam/DVU-Challenge/HLVU/keyframes/shot_keyf/honey/honey-2/shot_0012/shot_0012_img_1.jpg\n",
      "face_1\n",
      "WARNING: Representations for images in  /media/lkunam/DVU-Challenge/HLVU/movie_knowledge_graph/honey/image/Person/  folder were previously stored in  representations_vgg_face.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  54  representations found in  representations_vgg_face.pkl\n",
      "No face was able to be matched\n",
      "/media/lkunam/DVU-Challenge/HLVU/keyframes/shot_keyf/honey/honey-2/shot_0012/shot_0012_img_2.jpg\n",
      "face_1\n",
      "WARNING: Representations for images in  /media/lkunam/DVU-Challenge/HLVU/movie_knowledge_graph/honey/image/Person/  folder were previously stored in  representations_vgg_face.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  54  representations found in  representations_vgg_face.pkl\n",
      "No face was able to be matched\n",
      "/media/lkunam/DVU-Challenge/HLVU/keyframes/shot_keyf/honey/honey-2/shot_0012/shot_0012_img_0.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shot \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmovies\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshots\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmovies\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshots\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;66;03m#print(image)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;66;03m#print(f\"{img_path}/{movies}/{shots}/{shot}/{image}\")\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mRetinaFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mimg_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmovies\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mshots\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mshot\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mimage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;66;03m#print(len(resp))\u001b[39;00m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;66;03m#print(resp)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(resp) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(resp) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n",
      "File \u001b[0;32m/media/lkunam/DVU-Challenge/DVU-Master-Thesis/src/models/deepface/deepface/lib/python3.9/site-packages/retinaface/RetinaFace.py:76\u001b[0m, in \u001b[0;36mdetect_faces\u001b[0;34m(img_path, threshold, model)\u001b[0m\n\u001b[1;32m     74\u001b[0m landmarks_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     75\u001b[0m im_tensor, im_info, im_scale \u001b[38;5;241m=\u001b[39m preprocess\u001b[38;5;241m.\u001b[39mpreprocess_image(img)\n\u001b[0;32m---> 76\u001b[0m net_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m net_out \u001b[38;5;241m=\u001b[39m [elt\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m elt \u001b[38;5;129;01min\u001b[39;00m net_out]\n\u001b[1;32m     78\u001b[0m sym_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/media/lkunam/DVU-Challenge/DVU-Master-Thesis/src/models/deepface/deepface/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/media/lkunam/DVU-Challenge/DVU-Master-Thesis/src/models/deepface/deepface/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/media/lkunam/DVU-Challenge/DVU-Master-Thesis/src/models/deepface/deepface/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:981\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    977\u001b[0m   _, _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    978\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    979\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    980\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds, inner_filtered_flat_args):\n\u001b[1;32m    985\u001b[0m   \u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/media/lkunam/DVU-Challenge/DVU-Master-Thesis/src/models/deepface/deepface/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1958\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1961\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m     args,\n\u001b[1;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1964\u001b[0m     executing_eagerly)\n\u001b[1;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/media/lkunam/DVU-Challenge/DVU-Master-Thesis/src/models/deepface/deepface/lib/python3.9/site-packages/tensorflow/python/eager/function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    607\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    611\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/media/lkunam/DVU-Challenge/DVU-Master-Thesis/src/models/deepface/deepface/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from retinaface import RetinaFace\n",
    "from deepface import DeepFace\n",
    "from PIL import Image\n",
    "\n",
    "img_path = \"/media/lkunam/DVU-Challenge/HLVU/keyframes/shot_keyf\"\n",
    "\n",
    "#for movies in os.listdir(img_path):\n",
    "backends = ['opencv', 'ssd', 'dlib', 'mtcnn', 'retinaface']\n",
    "\n",
    "\n",
    "movies = \"honey\"\n",
    "shotlist = os.listdir(f\"{img_path}/{movies}\")\n",
    "orderedshotlist = [i.partition('-')[2] for i in shotlist]\n",
    "for i in range(len(shotlist)):\n",
    "    num = i+1\n",
    "    list_index = orderedshotlist.index(str(num))\n",
    "    shots = shotlist[list_index]\n",
    "    for shot in os.listdir(f\"{img_path}/{movies}/{shots}\"):\n",
    "        for image in os.listdir(f\"{img_path}/{movies}/{shots}/{shot}\"):\n",
    "            #print(image)\n",
    "            #print(f\"{img_path}/{movies}/{shots}/{shot}/{image}\")\n",
    "            resp = RetinaFace.detect_faces(f\"{img_path}/{movies}/{shots}/{shot}/{image}\")\n",
    "            #print(len(resp))\n",
    "            #print(resp)\n",
    "            if len(resp) > 0 and type(resp) == dict:\n",
    "                for face in resp:\n",
    "                    print(face)\n",
    "                    border = resp[face][\"facial_area\"]\n",
    "                    enlarged_border = enlargen_image(border)\n",
    "                    im = Image.open(f\"{img_path}/{movies}/{shots}/{shot}/{image}\")\n",
    "                    im1 = im.crop(border)\n",
    "                    im1.save(\"cropped.jpg\")\n",
    "                    try:\n",
    "                        df = DeepFace.find(img_path = \"cropped.jpg\", db_path = f\"/media/lkunam/DVU-Challenge/HLVU/movie_knowledge_graph/{movies}/image/Person/\", detector_backend = backends[4])\n",
    "                        result = df[\"identity\"][0]\n",
    "                        name = result[-17:].partition('/')[0]\n",
    "                        #name = \"{img_path}/{movies}/{shots}/{shot}/{image}\"\n",
    "                        shutil.copyfile(\"cropped.jpg\", f\"/media/lkunam/DVU-Challenge/HLVU/movie_knowledge_graph/{movies}/image/Person/{name}/{name}_new_{image[:-4]}\")\n",
    "                    except ValueError:\n",
    "                        print(\"No face was able to be matched\")\n",
    "                        print(f\"{img_path}/{movies}/{shots}/{shot}/{image}\")\n",
    "                        break\n",
    "    \n",
    "        \n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "working-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retinaface import RetinaFace\n",
    "from PIL import Image\n",
    "\n",
    "resp = RetinaFace.detect_faces(\"test4.jpg\")\n",
    "resp2 = RetinaFace.detect_faces(\"test3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fourth-small",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'face_1': {'score': 0.9981447458267212,\n",
       "  'facial_area': [416, 114, 511, 265],\n",
       "  'landmarks': {'right_eye': [432.88034, 178.34978],\n",
       "   'left_eye': [438.27887, 179.93327],\n",
       "   'nose': [419.61658, 214.01395],\n",
       "   'mouth_right': [453.28085, 233.6525],\n",
       "   'mouth_left': [455.96082, 233.37381]}},\n",
       " 'face_2': {'score': 0.9947980642318726,\n",
       "  'facial_area': [133, 90, 249, 218],\n",
       "  'landmarks': {'right_eye': [184.76659, 135.75351],\n",
       "   'left_eye': [231.91867, 153.49825],\n",
       "   'nose': [206.01382, 180.05284],\n",
       "   'mouth_right': [165.05785, 183.18796],\n",
       "   'mouth_left': [204.24113, 197.64708]}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "secret-oliver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Representations for images in  /media/lkunam/DVU-Challenge/HLVU/movie_knowledge_graph/honey/image/Person/  folder were previously stored in  representations_vgg_face.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  54  representations found in  representations_vgg_face.pkl\n",
      "No face was able to be matched\n",
      "WARNING: Representations for images in  /media/lkunam/DVU-Challenge/HLVU/movie_knowledge_graph/honey/image/Person/  folder were previously stored in  representations_vgg_face.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  54  representations found in  representations_vgg_face.pkl\n",
      "No face was able to be matched\n"
     ]
    }
   ],
   "source": [
    "for face in resp:\n",
    "    border = resp[face][\"facial_area\"]\n",
    "    im = Image.open(\"test3.jpg\")\n",
    "    im1 = im.crop(border)\n",
    "    im1.save(\"cropped.jpg\")\n",
    "    try:\n",
    "        df = DeepFace.find(img_path = \"cropped.jpg\", db_path = \"/media/lkunam/DVU-Challenge/HLVU/movie_knowledge_graph/honey/image/Person/\", detector_backend = backends[1])\n",
    "        result = df[\"identity\"][0]\n",
    "        print(result[-17:].partition('/')[0])\n",
    "    except ValueError:\n",
    "        print(\"No face was able to be matched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "north-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retinaface import RetinaFace\n",
    "from PIL import Image\n",
    "\n",
    "resp = RetinaFace.detect_faces(\"test4.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "opponent-antibody",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[416, 114, 511, 265]\n",
      "[133, 90, 249, 218]\n"
     ]
    }
   ],
   "source": [
    "for face in resp:\n",
    "    border = resp[face][\"facial_area\"]\n",
    "    print(border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "played-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"test3.jpg\")\n",
    "im1 = im.crop(border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "defined-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "im1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "vertical-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "im1.save(\"cropped.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "beneficial-black",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Representations for images in  /media/lkunam/DVU-Challenge/HLVU/movie_knowledge_graph/honey/image/Person/  folder were previously stored in  representations_vgg_face.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  54  representations found in  representations_vgg_face.pkl\n",
      "find function lasts  0.22999358177185059  seconds\n",
      "Marty\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "import os\n",
    "\n",
    "backends = ['opencv', 'ssd', 'dlib', 'mtcnn', 'retinaface']\n",
    "\n",
    "\n",
    "try:\n",
    "    df = DeepFace.find(img_path = \"test.jpg\", db_path = \"/media/lkunam/DVU-Challenge/HLVU/movie_knowledge_graph/honey/image/Person/\", detector_backend = backends[4])\n",
    "    result = df[\"identity\"][0]\n",
    "    print(result[-17:].partition('/')[0])\n",
    "except ValueError:\n",
    "    print(\"No face was able to be matched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "rapid-percentage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marty\n"
     ]
    }
   ],
   "source": [
    "result = df[\"identity\"][0]\n",
    "print(result[-17:].partition('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bulgarian-globe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  7.91it/s]\n"
     ]
    }
   ],
   "source": [
    "obj = DeepFace.analyze(img_path = \"../../images/apes.png\", actions = ['age', 'gender', 'race', 'emotion'],enforce_detection = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "vocational-elimination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 33, 'region': {'x': 0, 'y': 0, 'w': 624, 'h': 654}, 'gender': 'Man', 'race': {'asian': 2.6672628905544116e-05, 'indian': 0.0005696684183931211, 'black': 99.99924898147583, 'white': 2.11046757847555e-07, 'middle eastern': 3.3012492739459276e-07, 'latino hispanic': 0.0001600061636963801}, 'dominant_race': 'black', 'emotion': {'angry': 0.0011470142453617882, 'disgust': 2.4058101644186536e-05, 'fear': 0.01726231857901439, 'happy': 1.3578493148088455, 'sad': 97.93298840522766, 'surprise': 3.2087912188449863e-09, 'neutral': 0.6907255854457617}, 'dominant_emotion': 'sad'}\n"
     ]
    }
   ],
   "source": [
    "print(obj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepface",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
